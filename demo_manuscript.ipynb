{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sapphire-qualification",
   "metadata": {},
   "source": [
    "# MLflow tutorial with Anaconda virtual environments on lcoalholst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pacific-geography",
   "metadata": {},
   "source": [
    "*Based on https://www.youtube.com/watch?v=d60SAK4OOJY&t=906s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greatest-tokyo",
   "metadata": {},
   "source": [
    "Mlflow is used to control machine leanring life cycle to to record parameters, metrics, and library dependencies to secure experimental reproducability. And Mlflow is roughly compoed fo the following four components: Mlflow tracking, mlflow projects, mlflow models, and mlflow registry. And those processes are based on storage of log data recorded in mlflow tracking. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consistent-republic",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "![Mlflow Overviw](mlflow_overview.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "requested-group",
   "metadata": {},
   "source": [
    "## 1, Mlflow tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "terminal-liability",
   "metadata": {},
   "source": [
    "Taking logs of ML experiments with Mlflow tracking is at the basis of Mlflow. You can check performaces of each experience by each log.\n",
    "You have only to add some commands to take logs of paramters. If code is relatively, it would be btter to customize logs, but when it comes to deep learning, automaticlaly taking logs would be more convenient. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "golden-trance",
   "metadata": {},
   "source": [
    "![Mlflow Data Logging](mlflow_logs.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electoral-death",
   "metadata": {},
   "source": [
    "### Example: regression of wine data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imperial-heating",
   "metadata": {},
   "source": [
    "Please first install necessary libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silver-equivalent",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "south-bhutan",
   "metadata": {},
   "source": [
    "The most basic code introduced in Mlflow official tutorial uses ElasticNet in scikit-learn. The model predicts quality of wine given some features of wine in the data below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "intense-clarity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "csv_url = (\n",
    "        \"http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\"\n",
    "    )\n",
    "data = pd.read_csv(csv_url, sep=\";\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "informational-value",
   "metadata": {},
   "outputs": [],
   "source": [
    "!touch requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statewide-pride",
   "metadata": {},
   "source": [
    "The program of regression is easily done by runnign train_wine_regression.py, and parameters, metrics, and trained models are logged by mlflow.log_param(), mlflow.log_metric(), mlflow.sklearn.log_modle(), respectively. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "identified-state",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elasticnet model (alpha=0.500000, l1_ratio=0.500000):\r\n",
      "  RMSE: 0.7931640229276851\r\n",
      "  MAE: 0.6271946374319586\r\n",
      "  R2: 0.10862644997792614\r\n",
      "Model saved in run 16ba6a65177b4b0d81bf44a8078d7294\r\n"
     ]
    }
   ],
   "source": [
    "!python train_wine_regression.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "physical-composition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elasticnet model (alpha=0.600000, l1_ratio=0.400000):\r\n",
      "  RMSE: 0.7928446872861473\r\n",
      "  MAE: 0.626666444473971\r\n",
      "  R2: 0.10934405701835759\r\n",
      "Model saved in run 7cf97a38e2504b62bf449da7c931719a\r\n"
     ]
    }
   ],
   "source": [
    "!python train_wine_regression.py 0.6 0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swedish-talent",
   "metadata": {},
   "source": [
    "The logs are recorded in './mlruns/0' one after another. And directories of each experiment are constructed like below. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlike-foundation",
   "metadata": {},
   "source": [
    "*There are so many options for choosing where to log these tracking data, for example different places in localhost, databases, HTTP server, Databricks workspce. So I would like to keep examples here the most basic. For further details and options, please check scenarios in https://www.mlflow.org/docs/latest/tracking.html#where-runs-are-recorded "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "developing-tennis",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34mmlruns\u001b[0m\r\n",
      "└── \u001b[01;34m0\u001b[0m\r\n",
      "    ├── \u001b[01;34m16ba6a65177b4b0d81bf44a8078d7294\u001b[0m\r\n",
      "    │   ├── \u001b[01;34martifacts\u001b[0m\r\n",
      "    │   │   └── \u001b[01;34mmodel\u001b[0m\r\n",
      "    │   │       ├── \u001b[00mMLmodel\u001b[0m\r\n",
      "    │   │       ├── \u001b[00mconda.yaml\u001b[0m\r\n",
      "    │   │       ├── \u001b[00mmodel.pkl\u001b[0m\r\n",
      "    │   │       ├── \u001b[00mpython_env.yaml\u001b[0m\r\n",
      "    │   │       └── \u001b[00mrequirements.txt\u001b[0m\r\n",
      "    │   ├── \u001b[00mmeta.yaml\u001b[0m\r\n",
      "    │   ├── \u001b[01;34mmetrics\u001b[0m\r\n",
      "    │   │   ├── \u001b[00mmae\u001b[0m\r\n",
      "    │   │   ├── \u001b[00mr2\u001b[0m\r\n",
      "    │   │   └── \u001b[00mrmse\u001b[0m\r\n",
      "    │   ├── \u001b[01;34mparams\u001b[0m\r\n",
      "    │   │   ├── \u001b[00malpha\u001b[0m\r\n",
      "    │   │   └── \u001b[00ml1_ratio\u001b[0m\r\n",
      "    │   └── \u001b[01;34mtags\u001b[0m\r\n",
      "    │       ├── \u001b[00mmlflow.log-model.history\u001b[0m\r\n",
      "    │       ├── \u001b[00mmlflow.source.git.commit\u001b[0m\r\n",
      "    │       ├── \u001b[00mmlflow.source.name\u001b[0m\r\n",
      "    │       ├── \u001b[00mmlflow.source.type\u001b[0m\r\n",
      "    │       └── \u001b[00mmlflow.user\u001b[0m\r\n",
      "    ├── \u001b[01;34m7cf97a38e2504b62bf449da7c931719a\u001b[0m\r\n",
      "    │   ├── \u001b[01;34martifacts\u001b[0m\r\n",
      "    │   │   └── \u001b[01;34mmodel\u001b[0m\r\n",
      "    │   │       ├── \u001b[00mMLmodel\u001b[0m\r\n",
      "    │   │       ├── \u001b[00mconda.yaml\u001b[0m\r\n",
      "    │   │       ├── \u001b[00mmodel.pkl\u001b[0m\r\n",
      "    │   │       ├── \u001b[00mpython_env.yaml\u001b[0m\r\n",
      "    │   │       └── \u001b[00mrequirements.txt\u001b[0m\r\n",
      "    │   ├── \u001b[00mmeta.yaml\u001b[0m\r\n",
      "    │   ├── \u001b[01;34mmetrics\u001b[0m\r\n",
      "    │   │   ├── \u001b[00mmae\u001b[0m\r\n",
      "    │   │   ├── \u001b[00mr2\u001b[0m\r\n",
      "    │   │   └── \u001b[00mrmse\u001b[0m\r\n",
      "    │   ├── \u001b[01;34mparams\u001b[0m\r\n",
      "    │   │   ├── \u001b[00malpha\u001b[0m\r\n",
      "    │   │   └── \u001b[00ml1_ratio\u001b[0m\r\n",
      "    │   └── \u001b[01;34mtags\u001b[0m\r\n",
      "    │       ├── \u001b[00mmlflow.log-model.history\u001b[0m\r\n",
      "    │       ├── \u001b[00mmlflow.source.git.commit\u001b[0m\r\n",
      "    │       ├── \u001b[00mmlflow.source.name\u001b[0m\r\n",
      "    │       ├── \u001b[00mmlflow.source.type\u001b[0m\r\n",
      "    │       └── \u001b[00mmlflow.user\u001b[0m\r\n",
      "    └── \u001b[00mmeta.yaml\u001b[0m\r\n",
      "\r\n",
      "13 directories, 33 files\r\n"
     ]
    }
   ],
   "source": [
    "!tree mlruns #Installing tree is optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "muslim-lithuania",
   "metadata": {},
   "outputs": [],
   "source": [
    "You can check logs by accecing http://127.0.0.1:<port number> by running the following command. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "thirty-nigeria",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-06-15 14:04:30 +0900] [33446] [INFO] Starting gunicorn 20.1.0\n",
      "[2022-06-15 14:04:30 +0900] [33446] [INFO] Listening at: http://127.0.0.1:5000 (33446)\n",
      "[2022-06-15 14:04:30 +0900] [33446] [INFO] Using worker: sync\n",
      "[2022-06-15 14:04:30 +0900] [33448] [INFO] Booting worker with pid: 33448\n",
      "^C\n",
      "[2022-06-15 14:04:30 +0900] [33446] [INFO] Handling signal: int\n",
      "[2022-06-15 14:04:30 +0900] [33448] [INFO] Worker exiting (pid: 33448)\n"
     ]
    }
   ],
   "source": [
    "!mlflow ui"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moral-biodiversity",
   "metadata": {},
   "source": [
    "![Mlflow UI 1](mlflow_UI.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brave-witch",
   "metadata": {},
   "source": [
    "### Example: neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "promotional-surprise",
   "metadata": {},
   "source": [
    "When you run deep learning code, automaticlaly taking logs with mlflow.keras.autolog() is convenient. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "modified-insulation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "8982 train sequences\n",
      "2246 test sequences\n",
      "46 classes\n",
      "Vectorizing sequence data...\n",
      "x_train shape: (8982, 1000)\n",
      "x_test shape: (2246, 1000)\n",
      "Convert class vector to binary class matrix (for use with categorical_crossentropy)\n",
      "y_train shape: (8982, 46)\n",
      "y_test shape: (2246, 46)\n",
      "Building model...\n",
      "2022-06-15 13:33:18.375569: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022/06/15 13:33:18 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '72691d8862f04bf2bf363e4bbfdb1c34', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current tensorflow workflow\n",
      "Epoch 1/3\n",
      "81/81 [==============================] - 1s 5ms/step - loss: 1.7071 - accuracy: 0.6269 - val_loss: 1.2336 - val_accuracy: 0.7408\n",
      "Epoch 2/3\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 0.9648 - accuracy: 0.7799 - val_loss: 1.0444 - val_accuracy: 0.7675\n",
      "Epoch 3/3\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 0.7241 - accuracy: 0.8311 - val_loss: 0.9225 - val_accuracy: 0.7953\n",
      "2022/06/15 13:33:25 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/Users/tamurataito/opt/anaconda3/envs/mlflow_demo_env/lib/python3.8/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils.\"\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.8933 - accuracy: 0.7916\n",
      "Test score: 0.8933367729187012\n",
      "Test accuracy: 0.7916295528411865\n"
     ]
    }
   ],
   "source": [
    "!python sample_keras.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "decreased-distance",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "8982 train sequences\n",
      "2246 test sequences\n",
      "46 classes\n",
      "Vectorizing sequence data...\n",
      "x_train shape: (8982, 1000)\n",
      "x_test shape: (2246, 1000)\n",
      "Convert class vector to binary class matrix (for use with categorical_crossentropy)\n",
      "y_train shape: (8982, 46)\n",
      "y_test shape: (2246, 46)\n",
      "Building model...\n",
      "2022-06-15 13:42:06.152310: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022/06/15 13:42:06 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '44ef713a6960438484c7630e7eb8e1fb', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current tensorflow workflow\n",
      "Epoch 1/5\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 1.3986 - accuracy: 0.6876 - val_loss: 1.0850 - val_accuracy: 0.7653\n",
      "Epoch 2/5\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 0.7756 - accuracy: 0.8196 - val_loss: 0.9134 - val_accuracy: 0.7953\n",
      "Epoch 3/5\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 0.5468 - accuracy: 0.8677 - val_loss: 0.8597 - val_accuracy: 0.8109\n",
      "Epoch 4/5\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 0.4153 - accuracy: 0.8994 - val_loss: 0.8789 - val_accuracy: 0.8087\n",
      "Epoch 5/5\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 0.3291 - accuracy: 0.9156 - val_loss: 0.9081 - val_accuracy: 0.8076\n",
      "2022/06/15 13:42:15 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/Users/tamurataito/opt/anaconda3/envs/mlflow_demo_env/lib/python3.8/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils.\"\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.8923 - accuracy: 0.7947\n",
      "Test score: 0.8923482894897461\n",
      "Test accuracy: 0.7947462201118469\n"
     ]
    }
   ],
   "source": [
    "!python sample_keras.py --batch_size 32 --train_epochs 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "communist-bahrain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-06-15 13:42:32 +0900] [32341] [INFO] Starting gunicorn 20.1.0\n",
      "[2022-06-15 13:42:32 +0900] [32341] [INFO] Listening at: http://127.0.0.1:5000 (32341)\n",
      "[2022-06-15 13:42:32 +0900] [32341] [INFO] Using worker: sync\n",
      "[2022-06-15 13:42:32 +0900] [32343] [INFO] Booting worker with pid: 32343\n",
      "^C\n",
      "[2022-06-15 13:43:55 +0900] [32341] [INFO] Handling signal: int\n",
      "[2022-06-15 13:43:56 +0900] [32343] [INFO] Worker exiting (pid: 32343)\n"
     ]
    }
   ],
   "source": [
    "!mlflow ui"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marked-pledge",
   "metadata": {},
   "source": [
    "![Keras Metrics](keras_metric_logs.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "derived-discovery",
   "metadata": {},
   "source": [
    "### 2, Mlflow Projects\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saving-bandwidth",
   "metadata": {},
   "source": [
    "Mlflow Projects allow you to package experimental environments so that other poeple easily reproduce your experiements. You newly have only to prepare MLproject file because \"conda.yaml\" file is automatically generated in Mlflow Tracking. \"conda.yaml\" file describes version dependencies of libraries, and \"MLproject\" file describes which \n",
    "As long as these files are prepared, you can simulate the experimental settings easily also from GitHub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inclusive-property",
   "metadata": {},
   "source": [
    "![Mlflow Projects](mlflow_projects_overview.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "athletic-fountain",
   "metadata": {},
   "source": [
    "This Github link has necesasry files for packaging an experimental environment, thus we can set up an environment and run code with the following command."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "single-classification",
   "metadata": {},
   "source": [
    "*This command takes a while as it set up an virtual environemnt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "south-incident",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022/06/15 13:48:32 INFO mlflow.projects.utils: === Fetching project from https://github.com/mlflow/mlflow-example into /var/folders/n3/2_y2z9ns7js3zfs6xp0ls65m0000gn/T/tmpc1y5d11x ===\n",
      "2022/06/15 13:48:35 INFO mlflow.utils.conda: === Creating conda environment mlflow-1abc00771765dd9dd15731cbda4938c765fbb90b ===\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "Installing pip dependencies: \\ Ran pip subprocess with arguments:\n",
      "['/Users/tamurataito/opt/anaconda3/envs/mlflow-1abc00771765dd9dd15731cbda4938c765fbb90b/bin/python', '-m', 'pip', 'install', '-U', '-r', '/var/folders/n3/2_y2z9ns7js3zfs6xp0ls65m0000gn/T/tmpc1y5d11x/condaenv.08y8_x67.requirements.txt']\n",
      "Pip subprocess output:\n",
      "Collecting mlflow\n",
      "  Using cached mlflow-1.26.1-py3-none-any.whl (17.8 MB)\n",
      "Collecting protobuf>=3.12.0\n",
      "  Using cached protobuf-4.21.1-cp37-abi3-macosx_10_9_universal2.whl (483 kB)\n",
      "Collecting requests>=2.17.3\n",
      "  Using cached requests-2.28.0-py3-none-any.whl (62 kB)\n",
      "Collecting sqlparse>=0.3.1\n",
      "  Using cached sqlparse-0.4.2-py3-none-any.whl (42 kB)\n",
      "Collecting click>=7.0\n",
      "  Using cached click-8.1.3-py3-none-any.whl (96 kB)\n",
      "Collecting packaging\n",
      "  Using cached packaging-21.3-py3-none-any.whl (40 kB)\n",
      "Collecting importlib-metadata!=4.7.0,>=3.7.0\n",
      "  Using cached importlib_metadata-4.11.4-py3-none-any.whl (18 kB)\n",
      "Collecting Flask\n",
      "  Using cached Flask-2.1.2-py3-none-any.whl (95 kB)\n",
      "Requirement already satisfied: pandas in /Users/tamurataito/opt/anaconda3/envs/mlflow-1abc00771765dd9dd15731cbda4938c765fbb90b/lib/python3.7/site-packages (from mlflow->-r /var/folders/n3/2_y2z9ns7js3zfs6xp0ls65m0000gn/T/tmpc1y5d11x/condaenv.08y8_x67.requirements.txt (line 1)) (1.1.5)\n",
      "Collecting cloudpickle\n",
      "  Using cached cloudpickle-2.1.0-py3-none-any.whl (25 kB)\n",
      "Collecting alembic\n",
      "  Using cached alembic-1.8.0-py3-none-any.whl (209 kB)\n",
      "Collecting databricks-cli>=0.8.7\n",
      "  Using cached databricks_cli-0.16.7-py3-none-any.whl\n",
      "Collecting gunicorn\n",
      "  Using cached gunicorn-20.1.0-py3-none-any.whl (79 kB)\n",
      "Requirement already satisfied: pytz in /Users/tamurataito/opt/anaconda3/envs/mlflow-1abc00771765dd9dd15731cbda4938c765fbb90b/lib/python3.7/site-packages (from mlflow->-r /var/folders/n3/2_y2z9ns7js3zfs6xp0ls65m0000gn/T/tmpc1y5d11x/condaenv.08y8_x67.requirements.txt (line 1)) (2022.1)\n",
      "Collecting sqlalchemy\n",
      "  Using cached SQLAlchemy-1.4.37-cp37-cp37m-macosx_10_15_x86_64.whl (1.5 MB)\n",
      "Requirement already satisfied: scipy in /Users/tamurataito/opt/anaconda3/envs/mlflow-1abc00771765dd9dd15731cbda4938c765fbb90b/lib/python3.7/site-packages (from mlflow->-r /var/folders/n3/2_y2z9ns7js3zfs6xp0ls65m0000gn/T/tmpc1y5d11x/condaenv.08y8_x67.requirements.txt (line 1)) (1.1.0)\n",
      "Collecting prometheus-flask-exporter\n",
      "  Using cached prometheus_flask_exporter-0.20.2-py3-none-any.whl (18 kB)\n",
      "Collecting gitpython>=2.1.0\n",
      "  Using cached GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
      "Collecting docker>=4.0.0\n",
      "  Using cached docker-5.0.3-py2.py3-none-any.whl (146 kB)\n",
      "Collecting entrypoints\n",
      "  Using cached entrypoints-0.4-py3-none-any.whl (5.3 kB)\n",
      "Requirement already satisfied: numpy in /Users/tamurataito/opt/anaconda3/envs/mlflow-1abc00771765dd9dd15731cbda4938c765fbb90b/lib/python3.7/site-packages (from mlflow->-r /var/folders/n3/2_y2z9ns7js3zfs6xp0ls65m0000gn/T/tmpc1y5d11x/condaenv.08y8_x67.requirements.txt (line 1)) (1.15.4)\n",
      "Collecting querystring-parser\n",
      "  Using cached querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n",
      "Collecting pyyaml>=5.1\n",
      "  Using cached PyYAML-6.0-cp37-cp37m-macosx_10_9_x86_64.whl (189 kB)\n",
      "Collecting tabulate>=0.7.7\n",
      "  Using cached tabulate-0.8.9-py3-none-any.whl (25 kB)\n",
      "Collecting oauthlib>=3.1.0\n",
      "  Using cached oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "Collecting pyjwt>=1.7.0\n",
      "  Using cached PyJWT-2.4.0-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: six>=1.10.0 in /Users/tamurataito/opt/anaconda3/envs/mlflow-1abc00771765dd9dd15731cbda4938c765fbb90b/lib/python3.7/site-packages (from databricks-cli>=0.8.7->mlflow->-r /var/folders/n3/2_y2z9ns7js3zfs6xp0ls65m0000gn/T/tmpc1y5d11x/condaenv.08y8_x67.requirements.txt (line 1)) (1.16.0)\n",
      "Collecting websocket-client>=0.32.0\n",
      "  Using cached websocket_client-1.3.2-py3-none-any.whl (54 kB)\n",
      "Collecting typing-extensions>=3.7.4.3\n",
      "  Using cached typing_extensions-4.2.0-py3-none-any.whl (24 kB)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Using cached gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
      "Collecting smmap<6,>=3.0.1\n",
      "  Using cached smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Using cached zipp-3.8.0-py3-none-any.whl (5.4 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/tamurataito/opt/anaconda3/envs/mlflow-1abc00771765dd9dd15731cbda4938c765fbb90b/lib/python3.7/site-packages (from requests>=2.17.3->mlflow->-r /var/folders/n3/2_y2z9ns7js3zfs6xp0ls65m0000gn/T/tmpc1y5d11x/condaenv.08y8_x67.requirements.txt (line 1)) (2022.5.18.1)\n",
      "Collecting charset-normalizer~=2.0.0\n",
      "  Using cached charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Using cached urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.3-py3-none-any.whl (61 kB)\n",
      "Collecting Mako\n",
      "  Using cached Mako-1.2.0-py3-none-any.whl (78 kB)\n",
      "Collecting importlib-resources\n",
      "  Using cached importlib_resources-5.7.1-py3-none-any.whl (28 kB)\n",
      "Collecting greenlet!=0.4.17\n",
      "  Using cached greenlet-1.1.2-cp37-cp37m-macosx_10_14_x86_64.whl (92 kB)\n",
      "Collecting Jinja2>=3.0\n",
      "  Using cached Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
      "Collecting Werkzeug>=2.0\n",
      "  Using cached Werkzeug-2.1.2-py3-none-any.whl (224 kB)\n",
      "Collecting itsdangerous>=2.0\n",
      "  Using cached itsdangerous-2.1.2-py3-none-any.whl (15 kB)\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Using cached MarkupSafe-2.1.1-cp37-cp37m-macosx_10_9_x86_64.whl (13 kB)\n",
      "Requirement already satisfied: setuptools>=3.0 in /Users/tamurataito/opt/anaconda3/envs/mlflow-1abc00771765dd9dd15731cbda4938c765fbb90b/lib/python3.7/site-packages (from gunicorn->mlflow->-r /var/folders/n3/2_y2z9ns7js3zfs6xp0ls65m0000gn/T/tmpc1y5d11x/condaenv.08y8_x67.requirements.txt (line 1)) (61.2.0)\n",
      "Collecting pyparsing!=3.0.5,>=2.0.2\n",
      "  Using cached pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/tamurataito/opt/anaconda3/envs/mlflow-1abc00771765dd9dd15731cbda4938c765fbb90b/lib/python3.7/site-packages (from pandas->mlflow->-r /var/folders/n3/2_y2z9ns7js3zfs6xp0ls65m0000gn/T/tmpc1y5d11x/condaenv.08y8_x67.requirements.txt (line 1)) (2.8.2)\n",
      "Collecting prometheus-client\n",
      "  Using cached prometheus_client-0.14.1-py3-none-any.whl (59 kB)\n",
      "Installing collected packages: zipp, typing-extensions, MarkupSafe, importlib-metadata, Werkzeug, urllib3, smmap, Jinja2, itsdangerous, idna, greenlet, click, charset-normalizer, websocket-client, tabulate, sqlalchemy, requests, pyparsing, pyjwt, prometheus-client, oauthlib, Mako, importlib-resources, gitdb, Flask, sqlparse, querystring-parser, pyyaml, protobuf, prometheus-flask-exporter, packaging, gunicorn, gitpython, entrypoints, docker, databricks-cli, cloudpickle, alembic, mlflow\n",
      "Successfully installed Flask-2.1.2 Jinja2-3.1.2 Mako-1.2.0 MarkupSafe-2.1.1 Werkzeug-2.1.2 alembic-1.8.0 charset-normalizer-2.0.12 click-8.1.3 cloudpickle-2.1.0 databricks-cli-0.16.7 docker-5.0.3 entrypoints-0.4 gitdb-4.0.9 gitpython-3.1.27 greenlet-1.1.2 gunicorn-20.1.0 idna-3.3 importlib-metadata-4.11.4 importlib-resources-5.7.1 itsdangerous-2.1.2 mlflow-1.26.1 oauthlib-3.2.0 packaging-21.3 prometheus-client-0.14.1 prometheus-flask-exporter-0.20.2 protobuf-4.21.1 pyjwt-2.4.0 pyparsing-3.0.9 pyyaml-6.0 querystring-parser-1.2.4 requests-2.28.0 smmap-5.0.0 sqlalchemy-1.4.37 sqlparse-0.4.2 tabulate-0.8.9 typing-extensions-4.2.0 urllib3-1.26.9 websocket-client-1.3.2 zipp-3.8.0\n",
      "\n",
      "done\n",
      "#\n",
      "# To activate this environment, use\n",
      "#\n",
      "#     $ conda activate mlflow-1abc00771765dd9dd15731cbda4938c765fbb90b\n",
      "#\n",
      "# To deactivate an active environment, use\n",
      "#\n",
      "#     $ conda deactivate\n",
      "\n",
      "2022/06/15 13:50:08 INFO mlflow.projects.utils: === Created directory /var/folders/n3/2_y2z9ns7js3zfs6xp0ls65m0000gn/T/tmp8k7trc7i for downloading remote URIs passed to arguments of type 'path' ===\n",
      "2022/06/15 13:50:08 INFO mlflow.projects.backend.local: === Running command 'source /Users/tamurataito/opt/anaconda3/bin/../etc/profile.d/conda.sh && conda activate mlflow-1abc00771765dd9dd15731cbda4938c765fbb90b 1>&2 && python train.py 0.6 0.1' in run with ID 'bdef03f084d34dbd8c8470cc34facbc5' === \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/tamurataito/opt/anaconda3/envs/mlflow-1abc00771765dd9dd15731cbda4938c765fbb90b/lib/python3.7/site-packages/sklearn/utils/__init__.py:4: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  from collections import Sequence\n",
      "/Users/tamurataito/opt/anaconda3/envs/mlflow-1abc00771765dd9dd15731cbda4938c765fbb90b/lib/python3.7/site-packages/sklearn/model_selection/_split.py:18: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  from collections import Iterable\n",
      "/Users/tamurataito/opt/anaconda3/envs/mlflow-1abc00771765dd9dd15731cbda4938c765fbb90b/lib/python3.7/site-packages/sklearn/model_selection/_search.py:16: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  from collections import Mapping, namedtuple, defaultdict, Sequence\n",
      "Elasticnet model (alpha=0.600000, l1_ratio=0.100000):\n",
      "  RMSE: 0.7985733780987151\n",
      "  MAE: 0.6202991221099381\n",
      "  R2: 0.17633705471063543\n",
      "2022/06/15 13:50:56 INFO mlflow.projects: === Run (ID 'bdef03f084d34dbd8c8470cc34facbc5') succeeded ===\n"
     ]
    }
   ],
   "source": [
    "!mlflow run https://github.com/mlflow/mlflow-example -P alpha=0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unnecessary-comfort",
   "metadata": {},
   "outputs": [],
   "source": [
    "You can see the new tracking data is stored in mlruns/0 (as bdef03f084d34dbd8c8470cc34facbc5 in my case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "antique-borough",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m16ba6a65177b4b0d81bf44a8078d7294\u001b[m\u001b[m \u001b[34m8cbf0a32935b43759e93adc5c09a6ccf\u001b[m\u001b[m\r\n",
      "\u001b[34m44ef713a6960438484c7630e7eb8e1fb\u001b[m\u001b[m \u001b[34mbdef03f084d34dbd8c8470cc34facbc5\u001b[m\u001b[m\r\n",
      "\u001b[34m72691d8862f04bf2bf363e4bbfdb1c34\u001b[m\u001b[m meta.yaml\r\n",
      "\u001b[34m7cf97a38e2504b62bf449da7c931719a\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!ls mlruns/0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solar-charles",
   "metadata": {},
   "source": [
    "You can check that a virtual environments is created by the command below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "champion-farming",
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda info --envs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focused-charm",
   "metadata": {},
   "source": [
    "### 3, Mlflow Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sufficient-breakfast",
   "metadata": {},
   "source": [
    "Mlflow Models deploy trained models for a variety of downstreaming tasks for example real-time serving through REST API, batch inference on Apache Spark. Again there so many cases assumed. In am going to take an simple example of setting up an API with the wine regression model you trained, and giving a test input throuth HTTP. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informed-saver",
   "metadata": {},
   "source": [
    "![Mlflow Models](mlflow_models_overview.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liable-advantage",
   "metadata": {},
   "source": [
    "We will consider a case of predincting wine quality giving data below with the model we trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "biological-orchestra",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'columns': ['fixed acidity',\n",
       "  'volatile acidity',\n",
       "  'citric acid',\n",
       "  'residual sugar',\n",
       "  'chlorides',\n",
       "  'free sulfur dioxide',\n",
       "  'total sulfur dioxide',\n",
       "  'density',\n",
       "  'pH',\n",
       "  'sulphates',\n",
       "  'alcohol'],\n",
       " 'data': [[12.8, 0.029, 0.48, 0.98, 6.2, 29, 3.33, 1.2, 0.39, 75, 0.66]]}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\"columns\": [\"fixed acidity\", \"volatile acidity\", \"citric acid\", \"residual sugar\", \"chlorides\", \"free sulfur dioxide\", \"total sulfur dioxide\", \"density\", \"pH\", \"sulphates\", \"alcohol\"], \n",
    " \"data\": [[12.8, 0.029, 0.48, 0.98, 6.2, 29, 3.33, 1.2, 0.39, 75, 0.66]]}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "widespread-overall",
   "metadata": {},
   "source": [
    "Pease check one of your tracked data contains all the files necessary for using Mlflow Models by looking at directories under mlruns. The \"0440051e26cf4a3fa485bcce0c16220a\" below is replaced with a directory you made. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "realistic-bryan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLmodel          model.pkl        requirements.txt\r\n",
      "conda.yaml       python_env.yaml\r\n"
     ]
    }
   ],
   "source": [
    "!ls mlruns/0/7cf97a38e2504b62bf449da7c931719a/artifacts/model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approved-frederick",
   "metadata": {},
   "source": [
    "The trained model can be served to for example port 5001 with the command below. \n",
    "Another virtual environment is created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "steady-desperate",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022/06/15 13:56:24 INFO mlflow.models.cli: Selected backend for flavor 'python_function'\n",
      "2022/06/15 13:56:25 INFO mlflow.utils.conda: === Creating conda environment mlflow-5484d1ed727ebeea670316c57c44ad16123db937 ===\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.11.0\n",
      "  latest version: 4.13.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base conda\n",
      "\n",
      "\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "Installing pip dependencies: | Ran pip subprocess with arguments:\n",
      "['/Users/tamurataito/opt/anaconda3/envs/mlflow-5484d1ed727ebeea670316c57c44ad16123db937/bin/python', '-m', 'pip', 'install', '-U', '-r', '/Users/tamurataito/Documents/mlflow_datanomiq_demo_2/mlruns/0/7cf97a38e2504b62bf449da7c931719a/artifacts/model/condaenv.9ak3quxa.requirements.txt']\n",
      "Pip subprocess output:\n",
      "Collecting mlflow\n",
      "  Using cached mlflow-1.26.1-py3-none-any.whl (17.8 MB)\n",
      "Collecting cloudpickle==2.1.0\n",
      "  Using cached cloudpickle-2.1.0-py3-none-any.whl (25 kB)\n",
      "Collecting scikit-learn==1.1.1\n",
      "  Using cached scikit_learn-1.1.1-cp38-cp38-macosx_10_13_x86_64.whl (8.5 MB)\n",
      "Collecting numpy>=1.17.3\n",
      "  Using cached numpy-1.22.4-cp38-cp38-macosx_10_15_x86_64.whl (17.6 MB)\n",
      "Collecting joblib>=1.0.0\n",
      "  Using cached joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
      "Collecting scipy>=1.3.2\n",
      "  Using cached scipy-1.8.1-cp38-cp38-macosx_12_0_universal2.macosx_10_9_x86_64.whl (55.3 MB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting Flask\n",
      "  Using cached Flask-2.1.2-py3-none-any.whl (95 kB)\n",
      "Collecting pandas\n",
      "  Using cached pandas-1.4.2-cp38-cp38-macosx_10_9_x86_64.whl (11.0 MB)\n",
      "Collecting gunicorn\n",
      "  Using cached gunicorn-20.1.0-py3-none-any.whl (79 kB)\n",
      "Collecting click>=7.0\n",
      "  Using cached click-8.1.3-py3-none-any.whl (96 kB)\n",
      "Collecting querystring-parser\n",
      "  Using cached querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n",
      "Collecting prometheus-flask-exporter\n",
      "  Using cached prometheus_flask_exporter-0.20.2-py3-none-any.whl (18 kB)\n",
      "Collecting alembic\n",
      "  Using cached alembic-1.8.0-py3-none-any.whl (209 kB)\n",
      "Collecting gitpython>=2.1.0\n",
      "  Using cached GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
      "Collecting importlib-metadata!=4.7.0,>=3.7.0\n",
      "  Using cached importlib_metadata-4.11.4-py3-none-any.whl (18 kB)\n",
      "Collecting pytz\n",
      "  Using cached pytz-2022.1-py2.py3-none-any.whl (503 kB)\n",
      "Collecting entrypoints\n",
      "  Using cached entrypoints-0.4-py3-none-any.whl (5.3 kB)\n",
      "Collecting docker>=4.0.0\n",
      "  Using cached docker-5.0.3-py2.py3-none-any.whl (146 kB)\n",
      "Collecting pyyaml>=5.1\n",
      "  Using cached PyYAML-6.0-cp38-cp38-macosx_10_9_x86_64.whl (192 kB)\n",
      "Collecting sqlalchemy\n",
      "  Using cached SQLAlchemy-1.4.37-cp38-cp38-macosx_10_15_x86_64.whl (1.5 MB)\n",
      "Collecting sqlparse>=0.3.1\n",
      "  Using cached sqlparse-0.4.2-py3-none-any.whl (42 kB)\n",
      "Collecting packaging\n",
      "  Using cached packaging-21.3-py3-none-any.whl (40 kB)\n",
      "Collecting databricks-cli>=0.8.7\n",
      "  Using cached databricks_cli-0.16.7-py3-none-any.whl\n",
      "Collecting protobuf>=3.12.0\n",
      "  Using cached protobuf-4.21.1-cp37-abi3-macosx_10_9_universal2.whl (483 kB)\n",
      "Collecting requests>=2.17.3\n",
      "  Using cached requests-2.28.0-py3-none-any.whl (62 kB)\n",
      "Collecting six>=1.10.0\n",
      "  Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting tabulate>=0.7.7\n",
      "  Using cached tabulate-0.8.9-py3-none-any.whl (25 kB)\n",
      "Collecting pyjwt>=1.7.0\n",
      "  Using cached PyJWT-2.4.0-py3-none-any.whl (18 kB)\n",
      "Collecting oauthlib>=3.1.0\n",
      "  Using cached oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "Collecting websocket-client>=0.32.0\n",
      "  Using cached websocket_client-1.3.2-py3-none-any.whl (54 kB)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Using cached gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
      "Collecting smmap<6,>=3.0.1\n",
      "  Using cached smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/tamurataito/.local/lib/python3.8/site-packages (from importlib-metadata!=4.7.0,>=3.7.0->mlflow->-r /Users/tamurataito/Documents/mlflow_datanomiq_demo_2/mlruns/0/7cf97a38e2504b62bf449da7c931719a/artifacts/model/condaenv.9ak3quxa.requirements.txt (line 1)) (3.8.0)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2022.5.18.1-py3-none-any.whl (155 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.3-py3-none-any.whl (61 kB)\n",
      "Collecting charset-normalizer~=2.0.0\n",
      "  Using cached charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Using cached urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
      "Collecting Mako\n",
      "  Using cached Mako-1.2.0-py3-none-any.whl (78 kB)\n",
      "Requirement already satisfied: importlib-resources in /Users/tamurataito/.local/lib/python3.8/site-packages (from alembic->mlflow->-r /Users/tamurataito/Documents/mlflow_datanomiq_demo_2/mlruns/0/7cf97a38e2504b62bf449da7c931719a/artifacts/model/condaenv.9ak3quxa.requirements.txt (line 1)) (5.7.1)\n",
      "Collecting greenlet!=0.4.17\n",
      "  Using cached greenlet-1.1.2-cp38-cp38-macosx_10_14_x86_64.whl (92 kB)\n",
      "Collecting Jinja2>=3.0\n",
      "  Using cached Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
      "Collecting itsdangerous>=2.0\n",
      "  Using cached itsdangerous-2.1.2-py3-none-any.whl (15 kB)\n",
      "Collecting Werkzeug>=2.0\n",
      "  Using cached Werkzeug-2.1.2-py3-none-any.whl (224 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/tamurataito/.local/lib/python3.8/site-packages (from Jinja2>=3.0->Flask->mlflow->-r /Users/tamurataito/Documents/mlflow_datanomiq_demo_2/mlruns/0/7cf97a38e2504b62bf449da7c931719a/artifacts/model/condaenv.9ak3quxa.requirements.txt (line 1)) (2.1.1)\n",
      "Requirement already satisfied: setuptools>=3.0 in /Users/tamurataito/opt/anaconda3/envs/mlflow-5484d1ed727ebeea670316c57c44ad16123db937/lib/python3.8/site-packages (from gunicorn->mlflow->-r /Users/tamurataito/Documents/mlflow_datanomiq_demo_2/mlruns/0/7cf97a38e2504b62bf449da7c931719a/artifacts/model/condaenv.9ak3quxa.requirements.txt (line 1)) (62.3.4)\n",
      "Collecting pyparsing!=3.0.5,>=2.0.2\n",
      "  Using cached pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "Collecting python-dateutil>=2.8.1\n",
      "  Using cached python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
      "Collecting prometheus-client\n",
      "  Using cached prometheus_client-0.14.1-py3-none-any.whl (59 kB)\n",
      "Installing collected packages: Werkzeug, urllib3, smmap, six, Jinja2, itsdangerous, importlib-metadata, idna, greenlet, click, charset-normalizer, certifi, websocket-client, tabulate, sqlalchemy, requests, pytz, python-dateutil, pyparsing, pyjwt, prometheus-client, oauthlib, numpy, Mako, gitdb, Flask, threadpoolctl, sqlparse, scipy, querystring-parser, pyyaml, protobuf, prometheus-flask-exporter, pandas, packaging, joblib, gunicorn, gitpython, entrypoints, docker, databricks-cli, cloudpickle, alembic, scikit-learn, mlflow\n",
      "Successfully installed Flask-2.1.2 Jinja2-3.1.2 Mako-1.2.0 Werkzeug-2.1.2 alembic-1.8.0 certifi-2022.5.18.1 charset-normalizer-2.0.12 click-8.1.3 cloudpickle-2.1.0 databricks-cli-0.16.7 docker-5.0.3 entrypoints-0.4 gitdb-4.0.9 gitpython-3.1.27 greenlet-1.1.2 gunicorn-20.1.0 idna-3.3 importlib-metadata-4.11.4 itsdangerous-2.1.2 joblib-1.1.0 mlflow-1.26.1 numpy-1.22.4 oauthlib-3.2.0 packaging-21.3 pandas-1.4.2 prometheus-client-0.14.1 prometheus-flask-exporter-0.20.2 protobuf-4.21.1 pyjwt-2.4.0 pyparsing-3.0.9 python-dateutil-2.8.2 pytz-2022.1 pyyaml-6.0 querystring-parser-1.2.4 requests-2.28.0 scikit-learn-1.1.1 scipy-1.8.1 six-1.16.0 smmap-5.0.0 sqlalchemy-1.4.37 sqlparse-0.4.2 tabulate-0.8.9 threadpoolctl-3.1.0 urllib3-1.26.9 websocket-client-1.3.2\n",
      "\n",
      "done\n",
      "#\n",
      "# To activate this environment, use\n",
      "#\n",
      "#     $ conda activate mlflow-5484d1ed727ebeea670316c57c44ad16123db937\n",
      "#\n",
      "# To deactivate an active environment, use\n",
      "#\n",
      "#     $ conda deactivate\n",
      "\n",
      "2022/06/15 13:59:03 INFO mlflow.pyfunc.backend: === Running command 'source /Users/tamurataito/opt/anaconda3/bin/../etc/profile.d/conda.sh && conda activate mlflow-5484d1ed727ebeea670316c57c44ad16123db937 1>&2 && exec gunicorn --timeout=60 -b 127.0.0.1:5001 -w 1 ${GUNICORN_CMD_ARGS} -- mlflow.pyfunc.scoring_server.wsgi:app'\n",
      "[2022-06-15 13:59:04 +0900] [33360] [INFO] Starting gunicorn 20.1.0\n",
      "[2022-06-15 13:59:04 +0900] [33360] [INFO] Listening at: http://127.0.0.1:5001 (33360)\n",
      "[2022-06-15 13:59:04 +0900] [33360] [INFO] Using worker: sync\n",
      "[2022-06-15 13:59:04 +0900] [33369] [INFO] Booting worker with pid: 33369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\r\n",
      "[2022-06-15 14:00:46 +0900] [33360] [INFO] Handling signal: int\r\n",
      "[2022-06-15 14:00:46 +0900] [33369] [INFO] Worker exiting (pid: 33369)\r\n"
     ]
    }
   ],
   "source": [
    "!mlflow models serve -m ./mlruns/0/7cf97a38e2504b62bf449da7c931719a/artifacts/model -p 5001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boolean-commissioner",
   "metadata": {},
   "source": [
    "And please open another window and type in the command below on commandline while running the command above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moving-magnitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "curl -X POST -H \"Content-Type:application/json; format=pandas-split\"  --data '{\"columns\": [\"fixed acidity\", \"volatile acidity\", \"citric acid\", \"residual sugar\", \"chlorides\", \"free sulfur dioxide\", \"total sulfur dioxide\", \"density\", \"pH\", \"sulphates\", \"alcohol\"], \"data\": [[12.8, 0.029, 0.48, 0.98, 6.2, 29, 3.33, 1.2, 0.39, 75, 0.66]]}' http://localhost:5001/invocations \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "matched-tattoo",
   "metadata": {},
   "source": [
    "Then you will find a predicted result of wine rank by the regression model. In the case below, the predicted rank is 5.118. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "skilled-ballet",
   "metadata": {},
   "source": [
    "![Mlflow Models Inference](inference_API.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "according-diagnosis",
   "metadata": {},
   "source": [
    "## 4, Mlflow Registry\n",
    "\n",
    "Mlflow registry make versioning of models easier like in the window below. But in order to use Mlflow Registry, tracking data have to be saved in DB, so let me skip this this topic in this demo. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relative-analyst",
   "metadata": {},
   "source": [
    "![Mlflow Registry Versioning](oss_registry_3_overview.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "athletic-elements",
   "metadata": {},
   "source": [
    "## Further things to consider\n",
    "- Considering more use cases by using Docker, Databricks etc. so that several people can work together.\n",
    "- Logging and deployig trained deep learning models. \n",
    "- More practical deployment of trained modls, for example inputting a csv file and regressing data in it. \n",
    "- Versioning of those trianed models. \n",
    "\n",
    "Please let me know what you want to know more in detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tutorial-travel",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
